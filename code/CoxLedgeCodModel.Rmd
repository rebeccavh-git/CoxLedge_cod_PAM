---
title: "CoxLedge_cod_model"
author: "Becca Van Hoeck"
date: "10/14/2021"
output: html_document
---
https://github.com/rebeccavh-git/CoxLedge_cod_PAM

Research Questions: 

1. Is the timing of Atlantic cod spawning-associated vocalization, including grunt presence and rate, associated with environmental variables? 
2. Do these environmental associations fall within the variation observed in Massachusetts Bay? 

Data Source:
- Fixed station passive acoustic monitoring data from spawning season of 2013 and 2014 at 1 site on Cox Ledge 
- Data are summarized by cod grunt presence and grunt rate per hour during the spawning season.
- Massachusetts Bay data spans 10 years and spawning associations are previously published


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load packages

```{r}

library(lunar)
library(dplyr)
library(tidyr)
library(lubridate)
library(ggplot2)
#library(lme4)
#library(lmtest)
#library(pscl)
library(MuMIn)
library(emmeans)
library(circular)
library(doBy) # for summaryBy - can I use dplyr/ group_by instead?
library(glmmTMB)
library(gridExtra)

```

# Load data

```{r}
cox = read.csv("data/codCoxModelData.csv", header = TRUE)

```

# Transform predictors to circular or quadratic

```{r}
cox$SpawnSeason = factor(cox$SpawnSeason)

# Hour of the day
cox$shour = sin(2*pi*(cox$hour/24)) 
cox$chour = cos(2*pi*(cox$hour/24)) 

# Julian Day
cox$sday = sin(2*pi*(cox$J/365))
cox$cday = cos(2*pi*(cox$J/365))

cox$daySq = cox$J_center^2

# Lunar cycle  
cox$sLunar = sin(cox$lunarphase) 
cox$cLunar = cos(cox$lunarphase)

#Semi lunar cycle
cox$sLunar2 = sin(cox$lunar2)
cox$cLunar2 = cos(cox$lunar2)


```

# Explore zeros

```{r}
mean(cox$n_grunts) # mean n_grunts = 0.18

cox %>% summarise(sum(n_grunts == 0)/n()) # 96.3% zeros

ggplot(cox, aes(x = n_grunts))+
  geom_bar()

max(cox$n_grunts)

# mean day of grunt presence
PresenceOnly = cox[cox$presence >0,]
PresenceOnly$Jedit = PresenceOnly$J
PresenceOnly$Jedit[PresenceOnly$Jedit <=31] = PresenceOnly$Jedit[PresenceOnly$Jedit <=31]+365
meanDay = mean(PresenceOnly$Jedit)


```

## Grunt Presence: Build and evaluate Cox Ledge  Models

```{r}
#### Presence - binomial

global_P = glmmTMB(presence ~ SpawnSeason + sday + cday + sLunar + cLunar + sLunar2 + cLunar2 + shour + chour + (1|wk),
                   data = cox, family = binomial)

global_P_quadDay = glmmTMB(presence ~ SpawnSeason + J_center + daySq + sLunar + cLunar + sLunar2 + cLunar2 + shour + chour + (1|wk),
                   data = cox, family = binomial)


# treating day as a quadratic doesn't substantially improve fit, but it does make more mathematical sense
AIC(global_P, global_P_quadDay)
BIC(global_P, global_P_quadDay)

# Day as a quadratic term

bin1 = glmmTMB(presence ~ SpawnSeason + J_center + daySq + sLunar2 + cLunar2 + shour + chour + (1|wk),
                   data = cox, family = binomial)

bin2 = glmmTMB(presence ~ SpawnSeason + J_center + daySq + sLunar + cLunar + shour + chour + (1|wk),
                   data = cox, family = binomial)

bin3 = glmmTMB(presence ~ SpawnSeason + J_center + daySq + shour + chour + (1|wk),
                   data = cox, family = binomial)

#bin4 = glmmTMB(presence ~ SpawnSeason + J_center + daySq + sLunar + cLunar + shour + chour,
#                   data = cox, family = binomial)

# 2nd best model, but includes day as a circular variable. Delta AIC is 2.3 from global
#bin5 = glmmTMB(presence ~ SpawnSeason + sday + cday + sLunar + cLunar + shour + chour + (1|wk),
#                   data = cox, family = binomial)


model.sel(global_P_quadDay, bin1, bin2, bin3)


# global model is only marginally better than model without L2 terms
# Mass Bay bbest is the same as bin2

bin1 = glmmTMB(presence ~ SpawnSeason + sday + cday + sLunar2 + cLunar2 + shour + chour + (1|wk),
                   data = cox, family = binomial)

bin2 = glmmTMB(presence ~ SpawnSeason + sday + cday + sLunar + cLunar + shour + chour + (1|wk),
                   data = cox, family = binomial)

bin3 = glmmTMB(presence ~ SpawnSeason + sday + cday + shour + chour + (1|wk),
                   data = cox, family = binomial)

model.sel(global_P, bin1, bin2, bin3)
BIC(global_P, bin1, bin2, bin3)

## AIC gives global model as the best fit, BIC gives bin2 (without semi-lunar) as best fit

```

## Grunt Rate: Build and evaluate Cox Ledge models

```{r}
#### Rate: Zero-inflated negative binomial

# This threw multiple errors/warnings related to infinite or missing values, and na function evaluation
#global_R = glmmTMB(n_grunts ~ SpawnSeason + J_center + daySq + sLunar + cLunar + sLunar2 + cLunar2 + shour + chour + (1|wk),
#                   data = cox, family = nbinom1(), 
#                   ziformula = ~.)

global_R_nb2 = glmmTMB(n_grunts ~ SpawnSeason + J_center + daySq + sLunar + cLunar + sLunar2 + cLunar2 + shour + chour + (1|wk),
                   data = cox, family = nbinom2(),
                   ziformula = ~.)
#removed random effect of week and it fixed the model convergence problem
global_R_cDay = glmmTMB(n_grunts ~ SpawnSeason + sday + cday + sLunar + cLunar + sLunar2 + cLunar2 + shour + chour + (1|wk),
                   data = cox, family = nbinom2(),
                   ziformula = ~.-(1|wk))
  
zinb1 = glmmTMB(n_grunts ~ SpawnSeason + J_center + daySq + sLunar + cLunar + sLunar2 + cLunar2 + shour + chour + (1|wk),
                   data = cox, family = nbinom2(),
                   ziformula = ~. - sLunar2 -cLunar2)

zinb2 = glmmTMB(n_grunts ~ SpawnSeason + J_center + daySq + sLunar2 + cLunar2 + shour + chour + (1|wk),
                   data = cox, family = nbinom2(),
                   ziformula = ~. - sLunar2 -cLunar2)

# confirm that zero-inflation is needed
#nb1 = glmmTMB(n_grunts ~ SpawnSeason + J_center + daySq + sLunar + cLunar + sLunar2 + cLunar2 + shour + chour + (1|wk),
#                   data = cox, family = nbinom2())

model.sel(global_R_nb2, zinb1, zinb2)
#model.sel(global_R_nb2, zinb1, zinb2, nb1)

# Global model is still the best

## Day as a circular variable: remove (1|wk) from count process to allow model convergence
# effect of day is not significant in conditional model
global_R_cDay = glmmTMB(n_grunts ~ SpawnSeason + sday + cday + sLunar + cLunar + sLunar2 + cLunar2 + shour + chour + (1|wk),
                   data = cox, family = nbinom2(),
                   ziformula = ~.-(1|wk))
  
zinb1 = glmmTMB(n_grunts ~ SpawnSeason + sday + cday + sLunar + cLunar + sLunar2 + cLunar2 + shour + chour + (1|wk),
                   data = cox, family = nbinom2(),
                   ziformula = ~. - sLunar2 -cLunar2 -(1|wk))

zinb2 = glmmTMB(n_grunts ~ SpawnSeason + sday + cday + sLunar2 + cLunar2 + shour + chour + (1|wk),
                   data = cox, family = nbinom2(),
                   ziformula = ~. - sLunar2 -cLunar2 -(1|wk))

# deviation from Mass bay models - removed hour from conditional model bc it wasn't significant in global model
zinb3 = glmmTMB(n_grunts ~ SpawnSeason + sday + cday + sLunar + cLunar + sLunar2 + cLunar2 + (1|wk),
                   data = cox, family = nbinom2(),
                   ziformula = ~. +shour +chour-(1|wk))

# confirm that zero-inflation is needed
#nb1 = glmmTMB(n_grunts ~ SpawnSeason + sday + cday + sLunar + cLunar + sLunar2 + cLunar2 + shour + chour + (1|wk),
#                   data = cox, family = nbinom2())

model.sel(global_R_cDay, zinb1, zinb2, zinb3)
BIC(global_R_cDay, zinb1, zinb2, zinb3)

# Possible method explanation: started with a candidate model set as identified in Caiger et al. with some terms removed due to smaller study with only a single site. Compared support for each model using AIC, then to prevent overfitting removed any non-significant model terms and compared support with the best model identified from the candidate model set. 

```

## Summarize EM Means of best models 

```{r}
# Best Models
bbestCox = glmmTMB(presence ~ SpawnSeason + J_center + daySq + sLunar + cLunar + sLunar2 + cLunar2 + shour + chour + (1|wk),
                   data = cox, family = binomial)
# checking new presence model
bbestCox = bin2

#zbestCox = glmmTMB(n_grunts ~ SpawnSeason + J_center + daySq + sLunar + cLunar + sLunar2 + cLunar2 + shour + chour + (1|wk),
#                   data = cox, family = nbinom2(),
#                   ziformula = ~.)

# new zbestCox
#zbestCox = zinb3
zbestCox = glmmTMB(n_grunts ~ SpawnSeason + sday + cday + sLunar + cLunar + sLunar2 + cLunar2 + (1|wk),
                   data = cox, family = nbinom2(),
                   ziformula = ~. +shour +chour-(1|wk))


# Function to calculate reference grids
make_circ<-function(d){
    out<-d
    namez<-names(d)
    if("hour"%in%namez){
      out$shour<-sin(2*pi*(out$hour/24))
      out$chour<-cos(2*pi*(out$hour/24))
    }
    # if("day"%in%namez){  #original code for when model included circular day
    #   out$sday<-sin(2*pi*(out$day/365))
    #   out$cday<-cos(2*pi*(out$day/365))
    # }
    # if("day"%in%namez){  # my attempt to update this function for the circular variable (it didn't work)
    #   out$J_center<-out$J_center
    #   out$daysq<-out$J_center^2
    # }
    if("Lunar"%in%namez){
      out$sLunar<-sin(out$Lunar)
      out$cLunar<-cos(out$Lunar)
      out$Lunar2<-out$Lunar
      out$Lunar2[out$Lunar2>pi]<-out$Lunar2[out$Lunar2>pi]-pi
      out$Lunar2<-2*out$Lunar2
      out$sLunar2<-sin(out$Lunar2) #SEMI-LUNAR
      out$cLunar2<-cos(out$Lunar2) #SEMI-LUNAR
    }
    return(out)
}

## if keep models with day as circular: use this make_circ function
make_circ<-function(d){
  out<-d
  namez<-names(d)
  if("hour"%in%namez){
    out$shour<-sin(2*pi*(out$hour/24))
    out$chour<-cos(2*pi*(out$hour/24))
  }
  if("J"%in%namez){  #original code for when model included circular day
    out$sday<-sin(2*pi*(out$J/365))
    out$cday<-cos(2*pi*(out$J/365))
  }
  if("Lunar"%in%namez){
    out$sLunar<-sin(out$Lunar)
    out$cLunar<-cos(out$Lunar)
    out$Lunar2<-out$Lunar
    out$Lunar2[out$Lunar2>pi]<-out$Lunar2[out$Lunar2>pi]-pi
    out$Lunar2<-2*out$Lunar2
    out$sLunar2<-sin(out$Lunar2) #SEMI-LUNAR
    out$cLunar2<-cos(out$Lunar2) #SEMI-LUNAR
  }
  return(out)
}


# Averages: Midnight, Full moon, Day = 337 (mean day of presence)
# Compare predictions with day = 337 

## Diel EMM
# type=response did not change presence fit, but did change the CI and everything for the rate model
nd = expand.grid(SpawnSeason=as.character(unique(cox$SpawnSeason)), J_center=0.05631918, daySq=0.0031718495, Lunar=pi, hour=0:24, wk = NA)
nd = make_circ(nd)
nd = cbind(nd,as.data.frame(predict(bbestCox,newdata=nd,type='response',se.fit = TRUE)))
nd$lwrCIP = nd$fit + qnorm(0.025)*nd$se.fit 
nd$uprCIP = nd$fit + qnorm(0.975)*nd$se.fit 
nd$fittedP = nd$fit
ndRate = as.data.frame(predict(zbestCox,newdata=nd,type='response',se.fit = TRUE))
ndRate$lwrCIR = ndRate$fit + qnorm(0.025)*ndRate$se.fit # convert se to CI on link scale
ndRate$uprCIR = ndRate$fit + qnorm(0.975)*ndRate$se.fit 
ndRate$fittedR = ndRate$fit
nd = cbind(nd,ndRate[,c(3:5)])
emm_hCox = summaryBy(cbind(fittedP,lwrCIP,uprCIP,fittedR,lwrCIR,uprCIR)~hour,data=nd,FUN=mean,keep.names=TRUE)

## Lunar EMM
nd = expand.grid(SpawnSeason=as.character(unique(cox$SpawnSeason)), J_center=0.05631918, daySq=0.0031718495,
                    Lunar=seq(0,2*pi,length=16),hour=0, wk = NA)
nd = make_circ(nd)
nd = cbind(nd,as.data.frame(predict(bbestCox,newdata=nd,type='response',se.fit = TRUE)))
nd$lwrCIP = nd$fit + qnorm(0.025)*nd$se.fit 
nd$uprCIP = nd$fit + qnorm(0.975)*nd$se.fit 
nd$fittedP = nd$fit
ndRate = as.data.frame(predict(zbestCox,newdata=nd,type='response',se.fit = TRUE))
ndRate$lwrCIR = ndRate$fit + qnorm(0.025)*ndRate$se.fit # convert se to CI on link scale
ndRate$uprCIR = ndRate$fit + qnorm(0.975)*ndRate$se.fit 
ndRate$fittedR = ndRate$fit
nd = cbind(nd,ndRate[,c(3:5)])
emm_lCox = summaryBy(cbind(fittedP,lwrCIP,uprCIP,fittedR,lwrCIR,uprCIR)~Lunar,data=nd,FUN=mean,keep.names=TRUE)


## Annual effect - code mimicking Mass Bay method 
subsetJ = seq(1,123,by=3)
J = unique(cox$J)[subsetJ]
J_centerRange = unique(cox$J_center)[subsetJ]
daySq = J_centerRange^2
edate<-as.Date('2013-12-31')+J
df_j<-data.frame(J,J_centerRange,daySq,edate)
df_j$J_daySq = paste(df_j$J_centerRange, df_j$daySq, sep = "_")
emm_j_pg<-as.data.frame(emmeans(bbestCox,~J_center+daySq,at=list(J=J,J_center=J_centerRange,daySq=daySq)),type='response')
emm_j_rg<-as.data.frame(emmeans(zbestCox,~J_center+daySq,at=list(J=J,J_center=J_centerRange,daySq=daySq)),type='response')
emm_j_pg$J_daySq = paste(emm_j_pg$J_center,emm_j_pg$daySq, sep = "_")
emm_j_rg$J_daySq = paste(emm_j_rg$J_center,emm_j_rg$daySq, sep = "_")
emm_j_pg<-left_join(df_j,emm_j_pg, by = "J_daySq")
emm_j_rg<-left_join(df_j,emm_j_rg, by = "J_daySq")
#manually calculating CI from SE
emm_j_rg$lwrCIRm = emm_j_rg$response + qnorm(0.025)*emm_j_rg$SE # gives nonsensical neg lower CI, due to response scale
emm_j_rg$uprCIRm = emm_j_rg$response + qnorm(0.975)*emm_j_rg$SE # gives reasonable upper CI level

emm_jCox = df_j
emm_jCox$fittedP = emm_j_pg$prob
emm_jCox$lwrCIP = emm_j_pg$lower.CL
emm_jCox$uprCIP = emm_j_pg$upper.CL
emm_jCox$fittedR = emm_j_rg$response
emm_jCox$lwrCIR = emm_j_rg$lower.CL
emm_jCox$uprCIR = emm_j_rg$upper.CL

# plotting with lower CI as given by emmeans, upper CI as 2*SE to avoid unreasonable CI in October
# technically cheating
ggplot(data = emm_j_rg, aes(x = J_centerRange, y = response))+ theme_bw()+
  geom_line(size = 2, color = "blue")+
  geom_ribbon(aes(ymin = lower.CL, ymax = uprCIRm, alpha = 2), fill = "blue", show.legend = FALSE)+
  #scale_x_continuous(name = "J", breaks = c(274,304,334,,397), labels = c("Oct 01", "Nov 01","Dec 01", "Jan 01", "Feb 01"))+
  ylab("Predicted grunt rate")+
  theme(axis.title = element_text(size = 14),
        axis.text = element_text(size = 12))+
  ggtitle("Global Model (Day as quadratic, tz = EST, upper CI response+2*SE)")

# retrying old code with type = "response"
J_centerRange = unique(cox$J_center)
nd = expand.grid(SpawnSeason=as.character(unique(cox$SpawnSeason)),J_center=J_centerRange,Lunar=pi,hour=0,wk = NA)
nd$daySq = nd$J_center^2
nd = make_circ(nd)
nd = cbind(nd,as.data.frame(predict(bbestCox,newdata=nd,type='response',se.fit = TRUE)))
nd$fittedP = nd$fit 
nd$lwrCIP = nd$fit + qnorm(0.025)*nd$se.fit
nd$uprCIP =  nd$fit + qnorm(0.975)*nd$se.fit
ndRate = as.data.frame(predict(zbestCox,newdata=nd,type='response',se.fit = TRUE)) 
ndRate$lwrCIR = ndRate$fit + qnorm(0.025)*ndRate$se.fit 
ndRate$uprCIR = ndRate$fit + qnorm(0.975)*ndRate$se.fit 
ndRate$fittedR = ndRate$fit
nd = cbind(nd,ndRate)
emm_jCox = summaryBy(cbind(fittedP,lwrCIP,uprCIP,fittedR,lwrCIR,uprCIR)~J_center,data=nd,FUN=mean,keep.names=TRUE)
# This gives negative lower CI because it is supposed to be calculated on the link scale, 
# could likely fix by calculating CI using bootstrapping 

# retrying model with circular day rather than quadratic
# this works, but had to remove the random effect of week
# the peak rate of 12/14 seems pretty late based on observed data
# plus this model had a worse fit to the data than the original model with day as quadratic and random week
J<-seq(273,396,by=3)
sday<-sin(2*pi*(J/365))
cday<-cos(2*pi*(J/365))
edate<-as.Date('2010-12-31')+J
df_j<-data.frame(J,sday,cday,edate)
emm_j_rg<-as.data.frame(emmeans(zinb3,~sday+cday,at=list(J=J,sday=sday,cday=cday)),type='response')
emm_j_rg<-merge(df_j,emm_j_rg)

ggplot(data = emm_j_rg, aes(x = edate, y = response))+ theme_bw()+
  geom_line(size = 2, color = "blue")+
  geom_ribbon(aes(ymin = lower.CL, ymax = upper.CL, alpha = 2), fill = "blue", show.legend = FALSE)+
  #scale_x_continuous(name = "J", breaks = c(274,304,334,,397), labels = c("Oct 01", "Nov 01","Dec 01", "Jan 01", "Feb 01"))+
  ylab("Predicted grunt rate")+
  theme(axis.title = element_text(size = 14),
        axis.text = element_text(size = 12))+
  ggtitle("Global Model (Day as circular - no rW in rate terms)")


write.csv(emm_hCox, "data/emm_DielFX_Cox_v3.csv")
write.csv(emm_lCox,"data/emm_LunarFX_Cox_v3.csv")
write.csv(emm_jCox,"data/emm_AnnualFx_Cox_EST.csv") # original zbest model with EST
#write.csv()

```

## Summarize mass bay variation

Code below calculates the EM means from the mass bay model and re-creates their figures from the publication
```{r}
load("data/gsub.rdat")
load("data/pam_mixed_modz.rdat")

#SELECT BEST MODELS FOR PLOTTING 
bbest<-bmodz$b15
zbest<-zmodz$z18

## Micah's Functions
make_circ<-function(d){
    out<-d
    namez<-names(d)
    if("H"%in%namez){
      out$Hsin<-sin(2*pi*(out$H/24))
      out$Hcos<-cos(2*pi*(out$H/24))
    }
    if("J"%in%namez){
      out$Jsin<-sin(2*pi*(out$J/365))
      out$Jcos<-cos(2*pi*(out$J/365))
    }
    if("MOON"%in%namez){
      out$Msin<-sin(out$MOON)
      out$Mcos<-cos(out$MOON)
      out$MOON2<-out$MOON
      out$MOON2[out$MOON2>pi]<-out$MOON2[out$MOON2>pi]-pi
      out$MOON2<-2*out$MOON2
      out$Lsin<-sin(out$MOON2) #SEMI-LUNAR
      out$Lcos<-cos(out$MOON2) #SEMI-LUNAR
    }
    return(out)
  }
 
  
#EST MARGINAL MEANS
#MEAN ACROSS ALL YEARS & SITES, BUT AT MIDNIGHT, FULL MOON, NOV23

#DIEL FX
nd<-expand.grid(Y=as.character(unique(gsub$Y)),Site=as.character(unique(gsub$Site)),J=335,MOON=pi,H=0:24,WK=NA,DAY=NA,DEPTH=50)
nd<-make_circ(nd)
nd = cbind(nd,as.data.frame(predict(bbest,newdata=nd,type='response',se.fit = TRUE)))
nd$lwrCIP = nd$fit + qnorm(0.025)*nd$se.fit 
nd$uprCIP = nd$fit + qnorm(0.975)*nd$se.fit 
nd$fittedP = nd$fit
ndRate = as.data.frame(predict(zbest,newdata=nd,type='response',se.fit = TRUE))
ndRate$lwrCIR = ndRate$fit + qnorm(0.025)*ndRate$se.fit # convert se to CI on link scale
ndRate$uprCIR = ndRate$fit + qnorm(0.975)*ndRate$se.fit 
ndRate$fittedR = ndRate$fit
nd = cbind(nd,ndRate[,c(3:5)])
emm_hMB = summaryBy(cbind(fittedP,lwrCIP,uprCIP,fittedR,lwrCIR,uprCIR)~H,data=nd,FUN=mean,keep.names=TRUE)


#LUNAR FX
nd = expand.grid(Y=as.character(unique(gsub$Y)),Site=as.character(unique(gsub$Site)),J=335,MOON=seq(0,2*pi,length=16),H=0,WK=NA,DAY=NA,DEPTH=50)
nd = make_circ(nd)
nd = cbind(nd,as.data.frame(predict(bbest,newdata=nd,type='response',se.fit = TRUE)))
nd$lwrCIP = nd$fit + qnorm(0.025)*nd$se.fit 
nd$uprCIP = nd$fit + qnorm(0.975)*nd$se.fit 
nd$fittedP = nd$fit
ndRate = as.data.frame(predict(zbest,newdata=nd,type='response',se.fit = TRUE))
ndRate$lwrCIR = ndRate$fit + qnorm(0.025)*ndRate$se.fit 
ndRate$uprCIR = ndRate$fit + qnorm(0.975)*ndRate$se.fit 
ndRate$fittedR = ndRate$fit
nd = cbind(nd,ndRate[,c(3:5)])
emm_lMB = summaryBy(cbind(fittedP,lwrCIP,uprCIP,fittedR,lwrCIR,uprCIR)~MOON,data=nd,FUN=mean,keep.names=TRUE)


## Annual FX overall
# code actually used in Caiger et al for annual fx
emm_options(rg.limit = 200000)

J<-seq(273,365,by=3)
Jsin<-sin(2*pi*(J/365))
Jcos<-cos(2*pi*(J/365))
edate<-as.Date('2010-12-31')+J
df_j<-data.frame(J,Jsin,Jcos,edate)
emm_j_pg<-as.data.frame(emmeans(bbest,~Jsin+Jcos,at=list(J=J,Jsin=Jsin,Jcos=Jcos)),type='response')
emm_j_rg<-as.data.frame(emmeans(zbest,~Jsin+Jcos,at=list(J=J,Jsin=Jsin,Jcos=Jcos)),type='response')
emm_j_pg<-merge(df_j,emm_j_pg)
emm_j_rg<-merge(df_j,emm_j_rg)
# the merge function matches all instances of paired Jsin, Jcos in df_j with the corresponding response/prob and CI from emm_j

# remaking dataframe to match figure code
emm_jMB = as.data.frame(c(31:1))
colnames(emm_jMB) = "X"
emm_jMB$J = emm_j_pg$J
emm_jMB$edate = emm_j_pg$edate
emm_jMB$fittedP = emm_j_pg$prob
emm_jMB$lwrCIP = emm_j_pg$lower.CL
emm_jMB$uprCIP = emm_j_pg$upper.CL
emm_jMB$fittedR = emm_j_rg$response
emm_jMB$lwrCIR = emm_j_rg$lower.CL
emm_jMB$uprCIR = emm_j_rg$upper.CL



## Write Model fits to csv files since code takes prediction take so long to run
write.csv(emm_hMB, "data/emm_DielFX.csv")
write.csv(emm_lMB,"data/emm_LunarFX.csv")
write.csv(emm_jMB,"data/emm_AnnualFx_365.csv")
  
```

## Visualize EM Means and CI comparisons between Mass Bay and Cox Ledge

```{r}
# Cox Ledge
emm_hCox = read.csv("data/emm_DielFX_Cox_v2.csv", header = TRUE)
emm_lCox = read.csv("data/emm_LunarFX_Cox_v2.csv", header = TRUE)
#emm_jCox = read.csv("data/emm_AnnualFx_Cox_v2.csv", header = TRUE)
emm_jCox = read.csv("data/emm_AnnualFx_Cox_EST.csv", header = TRUE)

# Mass Bay
emm_hMB = read.csv("data/emm_DielFX.csv", header = TRUE)
emm_lMB = read.csv("data/emm_LunarFX.csv", header = TRUE)
emm_jMB = read.csv("data/emm_AnnualFx_365.csv", header = TRUE)

# Presence 

## Diel
dielPres = ggplot(data=emm_hMB, aes(x=H, y = fittedP))+ theme_bw()+
  coord_polar(start = 0)+
  geom_line(size = 1)+
  geom_ribbon(aes(ymin = lwrCIP, ymax = uprCIP,alpha = 2),show.legend = FALSE)+
  geom_line(data = emm_hCox, aes(x = hour, y = fittedP), size = 1, color = "blue")+
  geom_ribbon(data= emm_hCox, aes(x = hour, ymin = lwrCIP, ymax = uprCIP, alpha = 2), fill = "blue", show.legend = FALSE)+
  scale_x_continuous(name = "", breaks = c(6,12,18,24), labels = c("6", "12", "18","24"))+
  scale_y_continuous(name = "Grunt Presence")+
  theme(axis.title = element_text(size = 14),
        axis.text = element_text(size = 12))

## Lunar
lunarPres = ggplot(data=emm_lMB, aes(x=MOON, y = fittedP))+ theme_bw()+
  coord_polar(start = 0)+
  geom_line(size = 1)+
  geom_ribbon(aes(ymin = lwrCIP, ymax = uprCIP, alpha = 2), show.legend = FALSE)+
  geom_line(data = emm_lCox, aes(x = Lunar, y = fittedP), size = 1, color = "blue")+
  geom_ribbon(data= emm_lCox, aes(x = Lunar, ymin = lwrCIP, ymax = uprCIP, alpha = 2), fill = "blue", show.legend = FALSE)+
  scale_x_continuous(name = "", breaks = c(0,pi/2, pi, 3*pi/2),labels = c("New", "Waxing","Full","Waning"))+
  scale_y_continuous(name = "Grunt Presence")+
  theme(axis.title = element_text(size = 14),
        axis.text = element_text(size = 12))

grid.arrange(dielPres, lunarPres, ncol = 2)

## Annual 
ggplot()+ theme_bw()+
  geom_line(aes(x = X, y = fittedP), size = 2, data = emm_jMB)+
  geom_ribbon(aes(x = X, ymin = lwrCIP, ymax = uprCIP, alpha = 2), data = emm_jMB, show.legend = FALSE)+
  geom_line(aes(x = X, y = fittedP), size = 2, color = "blue", data = emm_jCox)+
  geom_ribbon(aes(x = X, ymin = lwrCIP, ymax = uprCIP, alpha = 2), data = emm_jCox, fill = "blue", show.legend = FALSE)+
  scale_x_continuous(name = "Date", breaks = c(1,11,21,31,42), labels = c("Oct 01", "Nov 01","Dec 01", "Jan 01", "Feb 01"))+
  ylab("Probability of grunt presence")+
  theme(axis.title = element_text(size = 14),
        axis.text = element_text(size = 12))


# Rate - separate graphs because of different scale between regions

# Diel 
dielMB = ggplot(data=emm_hMB, aes(x=H, y = fittedR))+ theme_bw()+
  coord_polar(start = 0)+
  geom_line(size = 1)+
  geom_ribbon(aes(ymin = lwrCIR, ymax = uprCIR, alpha = 2), show.legend = FALSE)+
  scale_x_continuous(name = "", breaks = c(6,12,18,24), labels = c("6", "12", "18","24"))+
  scale_y_continuous(name = "Grunt Rate")+
  theme(axis.title = element_text(size = 14),
        axis.text = element_text(size = 12))
dielCox = ggplot(data = emm_hCox, aes(x = hour, y = fittedR))+ theme_bw()+
  coord_polar(start = 0)+
  geom_line(size = 1, color = "blue")+
  geom_ribbon(aes(ymin = lwrCIR, ymax = uprCIR, alpha = 2), fill = "blue", show.legend = FALSE)+
  scale_x_continuous(name = "", breaks = c(6,12,18,24), labels = c("6", "12", "18","24"))+
  scale_y_continuous(name = "Grunt Rate")+
  theme(axis.title = element_text(size = 14),
        axis.text = element_text(size = 12))


## Lunar
lunarMB = ggplot(data=emm_lMB, aes(x=MOON, y = fittedR))+ theme_bw()+
  coord_polar(start = 0)+
  geom_line(size = 1)+
  geom_ribbon(aes(ymin = lwrCIR, ymax = uprCIR, alpha = 2), show.legend = FALSE)+
  scale_x_continuous(name = "", breaks = c(0,pi/2, pi, 3*pi/2),labels = c("New", "Waxing","Full","Waning"))+
  scale_y_continuous(name = "Grunt Rate")+
  theme(axis.title = element_text(size = 14),
        axis.text = element_text(size = 12))

lunarCox = ggplot(data=emm_lCox, aes(x=Lunar, y = fittedR))+ theme_bw()+
  coord_polar(start = 0)+
  geom_line(size = 1, color = "blue")+
  geom_ribbon(aes(ymin = lwrCIR, ymax = uprCIR, alpha = 2),fill = "blue", show.legend = FALSE)+
  scale_x_continuous(name = "", breaks = c(0,pi/2, pi, 3*pi/2),labels = c("New", "Waxing","Full","Waning"))+
  scale_y_continuous(name = "Grunt Rate")+
  theme(axis.title = element_text(size = 14),
        axis.text = element_text(size = 12))

grid.arrange(dielMB, dielCox, lunarMB, lunarCox, nrow = 2, ncol = 2)


# Day
DayMB = ggplot(data = emm_jMB, aes(x = X, y = fittedR))+ theme_bw()+
  geom_line(size = 2)+
  geom_ribbon(aes(ymin = lwrCIR, ymax = uprCIR, alpha = 2), show.legend = FALSE)+
  scale_x_continuous(name = "", breaks = c(1,11,21,32), labels = c("Oct 01", "Nov 01","Dec 01", "Jan 01"))+
  ylab("Predicted grunt rate")+
  theme(axis.title = element_text(size = 14),
        axis.text = element_text(size = 12))

DayCox = ggplot(data = emm_jCox, aes(x = X, y = fittedR))+ theme_bw()+
  geom_line(size = 2, color = "blue")+
  #geom_ribbon(aes(ymin = lwrCIR, ymax = uprCIR, alpha = 2), fill = "blue", show.legend = FALSE)+
  scale_x_continuous(name = "", breaks = c(1,11,21,31,42), labels = c("Oct 01", "Nov 01","Dec 01", "Jan 01", "Feb 01"))+
  ylab("Predicted grunt rate")+
  theme(axis.title = element_text(size = 14),
        axis.text = element_text(size = 12))+
  ggtitle("Global Model (Day as quadratic, tz = EST)")
 
grid.arrange(DayMB,DayCox,nrow = 1, ncol = 2)

## Annual FX Rate on single plot
# ggplot()+ theme_bw()+
#   geom_line(aes(x = X, y = fittedR), size = 2, data = emm_jMB)+
#   geom_ribbon(aes(x = X, ymin = lwrCIR, ymax = uprCIR, alpha = 2), data = emm_jMB, show.legend = FALSE)+
#   geom_line(aes(x = X, y = fittedR), size = 2, color = "blue", data = emm_jCox)+
#   geom_ribbon(aes(x = X, ymin = lwrCIR, ymax = uprCIR, alpha = 2), data = emm_jCox, fill = "blue", show.legend = FALSE)+
#   scale_x_continuous(name = "Date", breaks = c(1,11,21,31,42), labels = c("Oct 01", "Nov 01","Dec 01", "Jan 01", "Feb 01"))+
#   ylab("Predicted grunt rate")+
#   theme(axis.title = element_text(size = 14),
#         axis.text = element_text(size = 12))


# # Attempting figure for observed vs predicted at Cox Ledge each spawning season
# # With only one site, I don't think this figure is actually necessary
# # This predicts over every hour, I wanted just a prediction over each day - which is basically the plot above
# cox$fittedP = predict(bbestCox,newdata=cox,type='link',se.fit = FALSE)
# cox$predP = bbestCox$modelInfo$family$linkinv(cox$fittedP)
# 
# cox$fittedR = predict(zbestCox,newdata=cox,type='link',se.fit = FALSE)
# cox$predR =  zbestCox$modelInfo$family$linkinv(cox$fittedP)
# 
# # if want this figure need this code
# meanGruntHrDay = cod %>%
#   group_by(SpawnSeason, month, day) %>%
#   summarize(meanGrunt = mean(n_grunts))
# 
# meanGruntHrDay["month"][meanGruntHrDay["month"] == "1"] = 13
# meanGruntHrDay$monthday = paste(meanGruntHrDay$month, meanGruntHrDay$day, sep = "_")
# 
# # average grunts per hour on each day, (modeled after Zemeckis et al (2019) Fig 6)
# # add model predictions to these also
# ggplot(data = meanGruntHrDay, aes(x = monthday, y = meanGrunt))+ theme_bw()+
#   geom_col()+
#   scale_x_discrete(breaks = c("11_01","12_01","13_01"), 
#                   labels = c("Nov", "Dec", "Jan"))+
#   ylab("Average number of grunts per hour")+
#   facet_grid(rows = vars(SpawnSeason))+
#   theme(axis.title.x = element_blank())

```

